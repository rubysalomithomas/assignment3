{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xu4gQfrl2UK",
        "outputId": "6f8dc3a7-4ad6-4346-ec32-03e8344dfa80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 210kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.93MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 6.19MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Starting training...\n",
            "Epoch [1/20], Average Loss: 0.3838\n",
            "Epoch [1/20], Accuracy: 88.58%\n",
            "Best model saved to model.pt with accuracy: 88.58%\n",
            "Epoch [2/20], Average Loss: 0.2661\n",
            "Epoch [2/20], Accuracy: 90.47%\n",
            "Best model saved to model.pt with accuracy: 90.47%\n",
            "Epoch [3/20], Average Loss: 0.2264\n",
            "Epoch [3/20], Accuracy: 90.11%\n",
            "Epoch [4/20], Average Loss: 0.1946\n",
            "Epoch [4/20], Accuracy: 92.17%\n",
            "Best model saved to model.pt with accuracy: 92.17%\n",
            "Epoch [5/20], Average Loss: 0.1737\n",
            "Epoch [5/20], Accuracy: 91.80%\n",
            "Epoch [6/20], Average Loss: 0.1521\n",
            "Epoch [6/20], Accuracy: 92.17%\n",
            "Epoch [7/20], Average Loss: 0.1360\n",
            "Epoch [7/20], Accuracy: 92.44%\n",
            "Best model saved to model.pt with accuracy: 92.44%\n",
            "Epoch [8/20], Average Loss: 0.1184\n",
            "Epoch [8/20], Accuracy: 92.33%\n",
            "Epoch [9/20], Average Loss: 0.1058\n",
            "Epoch [9/20], Accuracy: 92.74%\n",
            "Best model saved to model.pt with accuracy: 92.74%\n",
            "Epoch [10/20], Average Loss: 0.0905\n",
            "Epoch [10/20], Accuracy: 92.94%\n",
            "Best model saved to model.pt with accuracy: 92.94%\n",
            "Epoch [11/20], Average Loss: 0.0814\n",
            "Epoch [11/20], Accuracy: 92.76%\n",
            "Epoch [12/20], Average Loss: 0.0687\n",
            "Epoch [12/20], Accuracy: 92.77%\n",
            "Epoch [13/20], Average Loss: 0.0654\n",
            "Epoch [13/20], Accuracy: 92.33%\n",
            "Epoch [14/20], Average Loss: 0.0606\n",
            "Epoch [14/20], Accuracy: 92.16%\n",
            "Epoch [15/20], Average Loss: 0.0536\n",
            "Epoch [15/20], Accuracy: 92.74%\n",
            "Epoch [16/20], Average Loss: 0.0476\n",
            "Epoch [16/20], Accuracy: 93.08%\n",
            "Best model saved to model.pt with accuracy: 93.08%\n",
            "Epoch [17/20], Average Loss: 0.0457\n",
            "Epoch [17/20], Accuracy: 92.37%\n",
            "Epoch [18/20], Average Loss: 0.0425\n",
            "Epoch [18/20], Accuracy: 92.48%\n",
            "Epoch [19/20], Average Loss: 0.0408\n",
            "Epoch [19/20], Accuracy: 92.57%\n",
            "Epoch [20/20], Average Loss: 0.0399\n",
            "Epoch [20/20], Accuracy: 92.55%\n",
            "\n",
            "completed!\n",
            "Best accuracy achieved: 93.08%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "\n",
        "class CustomFashionMNIST(Dataset):\n",
        "    def __init__(self, root='./data', train=True, transform=None):\n",
        "        self.original_dataset = datasets.FashionMNIST(\n",
        "            root=root,\n",
        "            train=train,\n",
        "            download=True\n",
        "        )\n",
        "\n",
        "        self.data = self.original_dataset.data.numpy()\n",
        "        self.targets = self.original_dataset.targets.numpy()\n",
        "        self.data = self.data.astype(np.float32) / 255.0\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.targets[idx]\n",
        "        image = torch.FloatTensor(image).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class FashionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def save_best_model(model, optimizer, epoch, accuracy):\n",
        "    \"\"\"Save only the best model weights based on accuracy.\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'accuracy': accuracy\n",
        "    }\n",
        "    best_filename = 'model.pt'\n",
        "    torch.save(checkpoint, best_filename)\n",
        "    print(f\"Best model saved to {best_filename} with accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_dataset = CustomFashionMNIST(train=True)\n",
        "    test_dataset = CustomFashionMNIST(train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # Create model\n",
        "    model = FashionNet().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training configuration\n",
        "    num_epochs = 20\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calculate average loss for the epoch\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                outputs = model(data)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += target.size(0)\n",
        "                correct += (predicted == target).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "        # Save only if this is the best accuracy so far\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            save_best_model(model, optimizer, epoch, accuracy)\n",
        "\n",
        "    print(f\"\\ncompleted!\")\n",
        "    print(f\"Best accuracy achieved: {best_accuracy:.2f}%\")\n"
      ]
    }
  ]
}